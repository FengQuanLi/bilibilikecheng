{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用pytorch构建两个参数的神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C=a*Z+b*J$\n",
    "\n",
    "可以用矩阵表示为：\n",
    "$$ \\begin{bmatrix}C\\end{bmatrix}=\\begin{bmatrix} a &b \\end{bmatrix} \\begin{bmatrix} Z \\\\ J  \\end{bmatrix}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "数据单元torch={}\n",
    "训练集torch=[]\n",
    "for i in range(100000):\n",
    "    鸡数=torch.randint(10000,(1,))[0] \n",
    "    兔数=torch.randint(10000,(1,))[0] \n",
    "    总只数=鸡数+兔数\n",
    "    总脚数=2*鸡数+4*兔数    \n",
    "    数据单元torch['鸡数']=鸡数\n",
    "    数据单元torch['输入数据']=torch.tensor([[总只数,总脚数]]).T\n",
    "    \n",
    "    训练集torch.append(数据单元torch.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建神经网络\n",
    "import torch.nn as nn\n",
    "class 求鸡的数量torch(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 初始化网络参数\n",
    "        self.ab = nn.Parameter(torch.rand(1,2))\n",
    "        #self.ab =nn.Parameter(torch.tensor(np.array([[1.,2.]]).reshape(1,2)).to(torch.float32))\n",
    "    def forward(self,输入):\n",
    "        \n",
    "        #C=self.ab.dot(输入)\n",
    "        C=torch.matmul(self.ab,输入)\n",
    "        #print(C)\n",
    "        #C=self.a*Z+self.b*J\n",
    "        return C[0,0]\n",
    "# 实例化一个神经网络\n",
    "预测鸡数torch=求鸡的数量torch()\n",
    "学习率=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 训练A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[119999.9609, -29999.9902]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.8147e-06, grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练\n",
    "for i in range(100000):\n",
    "    #取出一组数据\n",
    "    #并归一化\n",
    "    鸡数=训练集torch[i]['鸡数'].to(torch.float32)\n",
    "    输入=训练集torch[i]['输入数据']/60000\n",
    "    \n",
    "\n",
    "    鸡数_预=预测鸡数torch.forward(输入)\n",
    "\n",
    "    #损失函数\n",
    "    loss=(鸡数_预-鸡数)**2\n",
    "    \n",
    "    #损失函数对矩阵ab求导数\n",
    "    \n",
    "    loss_ab=2*(鸡数_预-鸡数)*输入.T\n",
    "    #print(loss,loss_ab)\n",
    "\n",
    "    #反向传播\n",
    "    #print(预测鸡数torch.ab.data)\n",
    "    预测鸡数torch.ab.data=预测鸡数torch.ab.data-学习率*loss_ab\n",
    "    \n",
    "print(预测鸡数torch.ab.data)    \n",
    "loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练—pyrorch通常用的方法  \n",
    "自动求导\n",
    "自带多种优化函数和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[119999.9609, -29999.9902]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.8147e-06, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "预测鸡数torch=求鸡的数量torch()\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(预测鸡数torch.parameters(), lr = 学习率)\n",
    "loss_fn = torch.nn.MSELoss(reduce=False, size_average=False)\n",
    "for i in range(100000):\n",
    "    #取出一组数据\n",
    "    #并归一化\n",
    "    鸡数=训练集torch[i]['鸡数'].to(torch.float32)\n",
    "    输入=训练集torch[i]['输入数据']/60000\n",
    "    \n",
    "\n",
    "    鸡数_预=预测鸡数torch(输入)\n",
    "    loss=loss_fn(鸡数_预,鸡数)\n",
    "\n",
    "    #损失函数\n",
    "    \n",
    "    \n",
    "    #反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(预测鸡数torch.ab.data)      \n",
    "loss  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "数据单元torch={}\n",
    "测试集torch=[]\n",
    "for i in range(1000):\n",
    "    鸡数=torch.randint(20000,(1,))[0] \n",
    "    兔数=torch.randint(20000,(1,))[0] \n",
    "    总只数=鸡数+兔数\n",
    "    总脚数=2*鸡数+4*兔数    \n",
    "    数据单元torch['鸡数']=鸡数\n",
    "    数据单元torch['输入数据']=torch.tensor([[总只数,总脚数]]).T\n",
    "    \n",
    "    测试集torch.append(数据单元torch.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000个测试数据正确1000个\n"
     ]
    }
   ],
   "source": [
    "正确数=0\n",
    "for i in range(1000):\n",
    "    #取出一组数据\n",
    "    #并归一化\n",
    "    鸡数=测试集torch[i]['鸡数']\n",
    "    输入=测试集torch[i]['输入数据']/60000\n",
    "    \n",
    "\n",
    "    鸡数_预=预测鸡数torch(输入)\n",
    "    鸡数_预=torch.round(鸡数_预)\n",
    "    #print(鸡数_预,鸡数)\n",
    "    if 鸡数_预==鸡数:\n",
    "        正确数+=1\n",
    "print('1000个测试数据正确{}个'.format(正确数))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "引入深度学习框架pytorch  \n",
    "pytorch 不仅仅可以自动求导，还打包了常用总损失函数和优化函数..........功能十分强大  \n",
    "[pytorch官方文档](https://pytorch.org/docs/stable/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
